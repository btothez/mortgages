{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this document, I continue to strive for high accuracy in predicting the classification of documents based on their anonymized words\n",
    "\n",
    "## However, in contrast to the previous effort, I take the order of the words into account here and employ a Recurrent Neural Network (specifically an LSTM). This ends up being important, because my resultant accuracy is 95.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import random\n",
    "df = pd.read_csv(\"shuffled-full-set-hashed.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's worth pointing out that my TF-IDF vectorizer here is much smaller, and that's because I re-trained it using only single words, not n-grams of up to 3. I did this for the size and speed of the vectorizer, but also because, we are taking word order into account for the LSTM beyond the n-gram length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = pickle.load(open('../server/webservice/pickles/encoder.pkl', 'rb'))\n",
    "smaller_vectorizer = pickle.load(open('./smaller_vectorizer.pkl', 'rb'))\n",
    "new_lsa = pickle.load(open('./new_lsa.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I begin by encoding the label for each row as a one-hot vector based on the encoded integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boaz.reisman/.virtualenvs/datascience/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label_vect(label):\n",
    "    vect = [0] * output_size\n",
    "    vect[label - 1] = 1\n",
    "    return vect\n",
    "\n",
    "output_size = len(encoder.classes_)\n",
    "sample = df[0:10000]\n",
    "sample.dropna(inplace=True)\n",
    "sample_y = sample[0]\n",
    "encoded_y = np.array([get_label_vect(l) for l in encoder.transform(sample_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\" Break a list into sized sub-lists \"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        new_chunk = l[i:i+n]\n",
    "        if len(new_chunk) < n:\n",
    "            new_chunk = ([''] * (n - len(new_chunk))) + new_chunk\n",
    "        yield new_chunk\n",
    "\n",
    "def word_2_vect(word):\n",
    "    \"\"\" For a word, transform into a wordvec \"\"\"\n",
    "    return new_lsa.transform(smaller_vectorizer.transform(pd.Series([word])))[0]        \n",
    "\n",
    "def get_batches(x, y, batch_size=300):\n",
    "    \"\"\" Break up input into batch-sized tensors \"\"\"\n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break the documents up into 20 word sized chunks, each associated with the correct label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 20\n",
    "training_set = []\n",
    "training_vects = []  \n",
    "        \n",
    "doc_arr = [x for x in sample[1]]\n",
    "doc_arr[0].split(' ')\n",
    "doc_words = [doc.split(' ') for doc in doc_arr]\n",
    "\n",
    "for i in range(len(doc_words)):\n",
    "    for chunk in chunks(doc_words[i], chunk_size):\n",
    "        training_set.append((encoded_y[i], chunk))     \n",
    "        \n",
    "random.shuffle(training_set)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, with our previously saved vectorizers, convert each of those words into 100-dimension vectors. Don't forget to save!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for label, chunk in training_set:\n",
    "    training_vects.append((label, [word_2_vect(word) for word in chunk]))\n",
    "    if i%500 == 0:\n",
    "        print('{} of {}'.format(i, len(training_set)))\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "i = 0\n",
    "for ch in chunks(training_vects, 80000):\n",
    "    pickle.dump(ch, open('training_vects_big_{}.pkl'.format(i), 'wb'))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_size = 256\n",
    "lstm_layers = 2\n",
    "batch_size = 500\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph object\n",
    "graph = tf.Graph()\n",
    "# Add nodes to the graph\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(\"float\", [None, chunk_size, 100])\n",
    "    labels_ = tf.placeholder(tf.int32, [None, output_size])\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we begin building our LSTM, First we create our two layers, each wrapped in a dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1003 20:04:28.423163 140736238351232 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1003 20:04:28.424947 140736238351232 deprecation.py:323] From <ipython-input-16-ab0169ed8749>:5: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W1003 20:04:28.431388 140736238351232 deprecation.py:323] From <ipython-input-16-ab0169ed8749>:10: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    with tf.name_scope(\"RNN_layers\"):\n",
    "        def lstm_cell():\n",
    "            lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size, reuse=tf.get_variable_scope().reuse)\n",
    "            return tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "\n",
    "        cell = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(lstm_layers)])\n",
    "        initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "        \n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, inputs_,\n",
    "                                             initial_state=initial_state)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we generate predictions, an output vector based on a logistic activation. The cost is the mean squared error with our one-hot label vectors, and our optimization algorithm, ADAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1003 20:04:43.100605 140736238351232 deprecation.py:323] From /Users/boaz.reisman/.virtualenvs/datascience/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    predictions = tf.contrib.layers.fully_connected(outputs[:, -1], output_size, activation_fn=tf.sigmoid)\n",
    "    cost = tf.losses.mean_squared_error(labels_, predictions)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we break up our cleaned data set into a training group, a validation group, and a testing group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prop = 0.8\n",
    "\n",
    "set_size = x.shape[0]\n",
    "\n",
    "split_idx = int(set_size*0.8)\n",
    "train_x, rest_x = x[:split_idx], x[split_idx:]\n",
    "train_y, rest_y = y[:split_idx], y[split_idx:]\n",
    "\n",
    "val_prop = 0.5\n",
    "rest_size = rest_x.shape[0]\n",
    "val_idx = int(val_prop * rest_size)\n",
    "val_x, test_x = rest_x[:val_idx], rest_x[val_idx:]\n",
    "val_y, test_y = rest_y[:val_idx], rest_y[val_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And run it through our LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10 Iteration: 5 Train loss: 0.195\n",
      "Epoch: 0/10 Iteration: 10 Train loss: 0.061\n",
      "Epoch: 0/10 Iteration: 15 Train loss: 0.062\n",
      "Epoch: 0/10 Iteration: 20 Train loss: 0.061\n",
      "Epoch: 0/10 Iteration: 25 Train loss: 0.058\n",
      "Val acc: 0.929\n",
      "Epoch: 0/10 Iteration: 30 Train loss: 0.060\n",
      "Epoch: 0/10 Iteration: 35 Train loss: 0.060\n",
      "Epoch: 0/10 Iteration: 40 Train loss: 0.058\n",
      "Epoch: 0/10 Iteration: 45 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 50 Train loss: 0.059\n",
      "Val acc: 0.929\n",
      "Epoch: 0/10 Iteration: 55 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 60 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 65 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 70 Train loss: 0.058\n",
      "Epoch: 0/10 Iteration: 75 Train loss: 0.058\n",
      "Val acc: 0.929\n",
      "Epoch: 0/10 Iteration: 80 Train loss: 0.058\n",
      "Epoch: 0/10 Iteration: 85 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 90 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 95 Train loss: 0.056\n",
      "Epoch: 0/10 Iteration: 100 Train loss: 0.057\n",
      "Val acc: 0.929\n",
      "Epoch: 0/10 Iteration: 105 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 110 Train loss: 0.055\n",
      "Epoch: 0/10 Iteration: 115 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 120 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 125 Train loss: 0.057\n",
      "Val acc: 0.929\n",
      "Epoch: 0/10 Iteration: 130 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 135 Train loss: 0.056\n",
      "Epoch: 0/10 Iteration: 140 Train loss: 0.056\n",
      "Epoch: 0/10 Iteration: 145 Train loss: 0.055\n",
      "Epoch: 0/10 Iteration: 150 Train loss: 0.056\n",
      "Val acc: 0.929\n",
      "Epoch: 0/10 Iteration: 155 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 160 Train loss: 0.056\n",
      "Epoch: 0/10 Iteration: 165 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 170 Train loss: 0.056\n",
      "Epoch: 0/10 Iteration: 175 Train loss: 0.056\n",
      "Val acc: 0.929\n",
      "Epoch: 0/10 Iteration: 180 Train loss: 0.056\n",
      "Epoch: 0/10 Iteration: 185 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 190 Train loss: 0.058\n",
      "Epoch: 0/10 Iteration: 195 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 200 Train loss: 0.057\n",
      "Val acc: 0.929\n",
      "Epoch: 0/10 Iteration: 205 Train loss: 0.056\n",
      "Epoch: 0/10 Iteration: 210 Train loss: 0.055\n",
      "Epoch: 0/10 Iteration: 215 Train loss: 0.056\n",
      "Epoch: 0/10 Iteration: 220 Train loss: 0.056\n",
      "Epoch: 0/10 Iteration: 225 Train loss: 0.057\n",
      "Val acc: 0.929\n",
      "Epoch: 0/10 Iteration: 230 Train loss: 0.055\n",
      "Epoch: 0/10 Iteration: 235 Train loss: 0.058\n",
      "Epoch: 0/10 Iteration: 240 Train loss: 0.056\n",
      "Epoch: 0/10 Iteration: 245 Train loss: 0.056\n",
      "Epoch: 0/10 Iteration: 250 Train loss: 0.056\n",
      "Val acc: 0.929\n",
      "Epoch: 0/10 Iteration: 255 Train loss: 0.056\n",
      "Epoch: 0/10 Iteration: 260 Train loss: 0.057\n",
      "Epoch: 0/10 Iteration: 265 Train loss: 0.055\n",
      "Epoch: 0/10 Iteration: 270 Train loss: 0.055\n",
      "Epoch: 1/10 Iteration: 275 Train loss: 0.057\n",
      "Val acc: 0.929\n",
      "Epoch: 1/10 Iteration: 280 Train loss: 0.056\n",
      "Epoch: 1/10 Iteration: 285 Train loss: 0.056\n",
      "Epoch: 1/10 Iteration: 290 Train loss: 0.056\n",
      "Epoch: 1/10 Iteration: 295 Train loss: 0.055\n",
      "Epoch: 1/10 Iteration: 300 Train loss: 0.056\n",
      "Val acc: 0.931\n",
      "Epoch: 1/10 Iteration: 305 Train loss: 0.056\n",
      "Epoch: 1/10 Iteration: 310 Train loss: 0.055\n",
      "Epoch: 1/10 Iteration: 315 Train loss: 0.057\n",
      "Epoch: 1/10 Iteration: 320 Train loss: 0.056\n",
      "Epoch: 1/10 Iteration: 325 Train loss: 0.051\n",
      "Val acc: 0.914\n",
      "Epoch: 1/10 Iteration: 330 Train loss: 0.054\n",
      "Epoch: 1/10 Iteration: 335 Train loss: 0.056\n",
      "Epoch: 1/10 Iteration: 340 Train loss: 0.056\n",
      "Epoch: 1/10 Iteration: 345 Train loss: 0.056\n",
      "Epoch: 1/10 Iteration: 350 Train loss: 0.054\n",
      "Val acc: 0.929\n",
      "Epoch: 1/10 Iteration: 355 Train loss: 0.055\n",
      "Epoch: 1/10 Iteration: 360 Train loss: 0.052\n",
      "Epoch: 1/10 Iteration: 365 Train loss: 0.050\n",
      "Epoch: 1/10 Iteration: 370 Train loss: 0.052\n",
      "Epoch: 1/10 Iteration: 375 Train loss: 0.052\n",
      "Val acc: 0.935\n",
      "Epoch: 1/10 Iteration: 380 Train loss: 0.053\n",
      "Epoch: 1/10 Iteration: 385 Train loss: 0.053\n",
      "Epoch: 1/10 Iteration: 390 Train loss: 0.052\n",
      "Epoch: 1/10 Iteration: 395 Train loss: 0.049\n",
      "Epoch: 1/10 Iteration: 400 Train loss: 0.047\n",
      "Val acc: 0.935\n",
      "Epoch: 1/10 Iteration: 405 Train loss: 0.048\n",
      "Epoch: 1/10 Iteration: 410 Train loss: 0.052\n",
      "Epoch: 1/10 Iteration: 415 Train loss: 0.048\n",
      "Epoch: 1/10 Iteration: 420 Train loss: 0.049\n",
      "Epoch: 1/10 Iteration: 425 Train loss: 0.048\n",
      "Val acc: 0.939\n",
      "Epoch: 1/10 Iteration: 430 Train loss: 0.048\n",
      "Epoch: 1/10 Iteration: 435 Train loss: 0.048\n",
      "Epoch: 1/10 Iteration: 440 Train loss: 0.047\n",
      "Epoch: 1/10 Iteration: 445 Train loss: 0.046\n",
      "Epoch: 1/10 Iteration: 450 Train loss: 0.045\n",
      "Val acc: 0.941\n",
      "Epoch: 1/10 Iteration: 455 Train loss: 0.049\n",
      "Epoch: 1/10 Iteration: 460 Train loss: 0.046\n",
      "Epoch: 1/10 Iteration: 465 Train loss: 0.046\n",
      "Epoch: 1/10 Iteration: 470 Train loss: 0.048\n",
      "Epoch: 1/10 Iteration: 475 Train loss: 0.049\n",
      "Val acc: 0.942\n",
      "Epoch: 1/10 Iteration: 480 Train loss: 0.048\n",
      "Epoch: 1/10 Iteration: 485 Train loss: 0.047\n",
      "Epoch: 1/10 Iteration: 490 Train loss: 0.045\n",
      "Epoch: 1/10 Iteration: 495 Train loss: 0.046\n",
      "Epoch: 1/10 Iteration: 500 Train loss: 0.047\n",
      "Val acc: 0.942\n",
      "Epoch: 1/10 Iteration: 505 Train loss: 0.046\n",
      "Epoch: 1/10 Iteration: 510 Train loss: 0.044\n",
      "Epoch: 1/10 Iteration: 515 Train loss: 0.046\n",
      "Epoch: 1/10 Iteration: 520 Train loss: 0.043\n",
      "Epoch: 1/10 Iteration: 525 Train loss: 0.044\n",
      "Val acc: 0.944\n",
      "Epoch: 1/10 Iteration: 530 Train loss: 0.046\n",
      "Epoch: 1/10 Iteration: 535 Train loss: 0.045\n",
      "Epoch: 1/10 Iteration: 540 Train loss: 0.046\n",
      "Epoch: 2/10 Iteration: 545 Train loss: 0.045\n",
      "Epoch: 2/10 Iteration: 550 Train loss: 0.047\n",
      "Val acc: 0.944\n",
      "Epoch: 2/10 Iteration: 555 Train loss: 0.046\n",
      "Epoch: 2/10 Iteration: 560 Train loss: 0.047\n",
      "Epoch: 2/10 Iteration: 565 Train loss: 0.046\n",
      "Epoch: 2/10 Iteration: 570 Train loss: 0.045\n",
      "Epoch: 2/10 Iteration: 575 Train loss: 0.046\n",
      "Val acc: 0.945\n",
      "Epoch: 2/10 Iteration: 580 Train loss: 0.042\n",
      "Epoch: 2/10 Iteration: 585 Train loss: 0.047\n",
      "Epoch: 2/10 Iteration: 590 Train loss: 0.044\n",
      "Epoch: 2/10 Iteration: 595 Train loss: 0.044\n",
      "Epoch: 2/10 Iteration: 600 Train loss: 0.046\n",
      "Val acc: 0.943\n",
      "Epoch: 2/10 Iteration: 605 Train loss: 0.048\n",
      "Epoch: 2/10 Iteration: 610 Train loss: 0.046\n",
      "Epoch: 2/10 Iteration: 615 Train loss: 0.048\n",
      "Epoch: 2/10 Iteration: 620 Train loss: 0.042\n",
      "Epoch: 2/10 Iteration: 625 Train loss: 0.046\n",
      "Val acc: 0.944\n",
      "Epoch: 2/10 Iteration: 630 Train loss: 0.041\n",
      "Epoch: 2/10 Iteration: 635 Train loss: 0.040\n",
      "Epoch: 2/10 Iteration: 640 Train loss: 0.045\n",
      "Epoch: 2/10 Iteration: 645 Train loss: 0.044\n",
      "Epoch: 2/10 Iteration: 650 Train loss: 0.046\n",
      "Val acc: 0.946\n",
      "Epoch: 2/10 Iteration: 655 Train loss: 0.044\n",
      "Epoch: 2/10 Iteration: 660 Train loss: 0.044\n",
      "Epoch: 2/10 Iteration: 665 Train loss: 0.046\n",
      "Epoch: 2/10 Iteration: 670 Train loss: 0.046\n",
      "Epoch: 2/10 Iteration: 675 Train loss: 0.043\n",
      "Val acc: 0.947\n",
      "Epoch: 2/10 Iteration: 680 Train loss: 0.043\n",
      "Epoch: 2/10 Iteration: 685 Train loss: 0.042\n",
      "Epoch: 2/10 Iteration: 690 Train loss: 0.043\n",
      "Epoch: 2/10 Iteration: 695 Train loss: 0.045\n",
      "Epoch: 2/10 Iteration: 700 Train loss: 0.043\n",
      "Val acc: 0.946\n",
      "Epoch: 2/10 Iteration: 705 Train loss: 0.040\n",
      "Epoch: 2/10 Iteration: 710 Train loss: 0.041\n",
      "Epoch: 2/10 Iteration: 715 Train loss: 0.042\n",
      "Epoch: 2/10 Iteration: 720 Train loss: 0.042\n",
      "Epoch: 2/10 Iteration: 725 Train loss: 0.044\n",
      "Val acc: 0.947\n",
      "Epoch: 2/10 Iteration: 730 Train loss: 0.041\n",
      "Epoch: 2/10 Iteration: 735 Train loss: 0.044\n",
      "Epoch: 2/10 Iteration: 740 Train loss: 0.043\n",
      "Epoch: 2/10 Iteration: 745 Train loss: 0.042\n",
      "Epoch: 2/10 Iteration: 750 Train loss: 0.040\n",
      "Val acc: 0.947\n",
      "Epoch: 2/10 Iteration: 755 Train loss: 0.041\n",
      "Epoch: 2/10 Iteration: 760 Train loss: 0.043\n",
      "Epoch: 2/10 Iteration: 765 Train loss: 0.042\n",
      "Epoch: 2/10 Iteration: 770 Train loss: 0.041\n",
      "Epoch: 2/10 Iteration: 775 Train loss: 0.043\n",
      "Val acc: 0.948\n",
      "Epoch: 2/10 Iteration: 780 Train loss: 0.042\n",
      "Epoch: 2/10 Iteration: 785 Train loss: 0.045\n",
      "Epoch: 2/10 Iteration: 790 Train loss: 0.043\n",
      "Epoch: 2/10 Iteration: 795 Train loss: 0.042\n",
      "Epoch: 2/10 Iteration: 800 Train loss: 0.044\n",
      "Val acc: 0.948\n",
      "Epoch: 2/10 Iteration: 805 Train loss: 0.039\n",
      "Epoch: 2/10 Iteration: 810 Train loss: 0.041\n",
      "Epoch: 2/10 Iteration: 815 Train loss: 0.043\n",
      "Epoch: 3/10 Iteration: 820 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 825 Train loss: 0.042\n",
      "Val acc: 0.948\n",
      "Epoch: 3/10 Iteration: 830 Train loss: 0.044\n",
      "Epoch: 3/10 Iteration: 835 Train loss: 0.042\n",
      "Epoch: 3/10 Iteration: 840 Train loss: 0.042\n",
      "Epoch: 3/10 Iteration: 845 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 850 Train loss: 0.042\n",
      "Val acc: 0.948\n",
      "Epoch: 3/10 Iteration: 855 Train loss: 0.042\n",
      "Epoch: 3/10 Iteration: 860 Train loss: 0.043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10 Iteration: 865 Train loss: 0.045\n",
      "Epoch: 3/10 Iteration: 870 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 875 Train loss: 0.041\n",
      "Val acc: 0.947\n",
      "Epoch: 3/10 Iteration: 880 Train loss: 0.043\n",
      "Epoch: 3/10 Iteration: 885 Train loss: 0.043\n",
      "Epoch: 3/10 Iteration: 890 Train loss: 0.040\n",
      "Epoch: 3/10 Iteration: 895 Train loss: 0.040\n",
      "Epoch: 3/10 Iteration: 900 Train loss: 0.042\n",
      "Val acc: 0.948\n",
      "Epoch: 3/10 Iteration: 905 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 910 Train loss: 0.043\n",
      "Epoch: 3/10 Iteration: 915 Train loss: 0.040\n",
      "Epoch: 3/10 Iteration: 920 Train loss: 0.039\n",
      "Epoch: 3/10 Iteration: 925 Train loss: 0.041\n",
      "Val acc: 0.948\n",
      "Epoch: 3/10 Iteration: 930 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 935 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 940 Train loss: 0.039\n",
      "Epoch: 3/10 Iteration: 945 Train loss: 0.042\n",
      "Epoch: 3/10 Iteration: 950 Train loss: 0.043\n",
      "Val acc: 0.949\n",
      "Epoch: 3/10 Iteration: 955 Train loss: 0.040\n",
      "Epoch: 3/10 Iteration: 960 Train loss: 0.040\n",
      "Epoch: 3/10 Iteration: 965 Train loss: 0.042\n",
      "Epoch: 3/10 Iteration: 970 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 975 Train loss: 0.043\n",
      "Val acc: 0.950\n",
      "Epoch: 3/10 Iteration: 980 Train loss: 0.043\n",
      "Epoch: 3/10 Iteration: 985 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 990 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 995 Train loss: 0.039\n",
      "Epoch: 3/10 Iteration: 1000 Train loss: 0.042\n",
      "Val acc: 0.949\n",
      "Epoch: 3/10 Iteration: 1005 Train loss: 0.042\n",
      "Epoch: 3/10 Iteration: 1010 Train loss: 0.039\n",
      "Epoch: 3/10 Iteration: 1015 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 1020 Train loss: 0.037\n",
      "Epoch: 3/10 Iteration: 1025 Train loss: 0.040\n",
      "Val acc: 0.949\n",
      "Epoch: 3/10 Iteration: 1030 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 1035 Train loss: 0.040\n",
      "Epoch: 3/10 Iteration: 1040 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 1045 Train loss: 0.037\n",
      "Epoch: 3/10 Iteration: 1050 Train loss: 0.040\n",
      "Val acc: 0.950\n",
      "Epoch: 3/10 Iteration: 1055 Train loss: 0.040\n",
      "Epoch: 3/10 Iteration: 1060 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 1065 Train loss: 0.038\n",
      "Epoch: 3/10 Iteration: 1070 Train loss: 0.037\n",
      "Epoch: 3/10 Iteration: 1075 Train loss: 0.041\n",
      "Val acc: 0.950\n",
      "Epoch: 3/10 Iteration: 1080 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 1085 Train loss: 0.038\n",
      "Epoch: 4/10 Iteration: 1090 Train loss: 0.041\n",
      "Epoch: 4/10 Iteration: 1095 Train loss: 0.041\n",
      "Epoch: 4/10 Iteration: 1100 Train loss: 0.041\n",
      "Val acc: 0.947\n",
      "Epoch: 4/10 Iteration: 1105 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 1110 Train loss: 0.041\n",
      "Epoch: 4/10 Iteration: 1115 Train loss: 0.040\n",
      "Epoch: 4/10 Iteration: 1120 Train loss: 0.042\n",
      "Epoch: 4/10 Iteration: 1125 Train loss: 0.043\n",
      "Val acc: 0.947\n",
      "Epoch: 4/10 Iteration: 1130 Train loss: 0.041\n",
      "Epoch: 4/10 Iteration: 1135 Train loss: 0.042\n",
      "Epoch: 4/10 Iteration: 1140 Train loss: 0.041\n",
      "Epoch: 4/10 Iteration: 1145 Train loss: 0.040\n",
      "Epoch: 4/10 Iteration: 1150 Train loss: 0.040\n",
      "Val acc: 0.947\n",
      "Epoch: 4/10 Iteration: 1155 Train loss: 0.040\n",
      "Epoch: 4/10 Iteration: 1160 Train loss: 0.041\n",
      "Epoch: 4/10 Iteration: 1165 Train loss: 0.038\n",
      "Epoch: 4/10 Iteration: 1170 Train loss: 0.041\n",
      "Epoch: 4/10 Iteration: 1175 Train loss: 0.041\n",
      "Val acc: 0.948\n",
      "Epoch: 4/10 Iteration: 1180 Train loss: 0.041\n",
      "Epoch: 4/10 Iteration: 1185 Train loss: 0.040\n",
      "Epoch: 4/10 Iteration: 1190 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 1195 Train loss: 0.036\n",
      "Epoch: 4/10 Iteration: 1200 Train loss: 0.037\n",
      "Val acc: 0.946\n",
      "Epoch: 4/10 Iteration: 1205 Train loss: 0.043\n",
      "Epoch: 4/10 Iteration: 1210 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 1215 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 1220 Train loss: 0.040\n",
      "Epoch: 4/10 Iteration: 1225 Train loss: 0.040\n",
      "Val acc: 0.947\n",
      "Epoch: 4/10 Iteration: 1230 Train loss: 0.043\n",
      "Epoch: 4/10 Iteration: 1235 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 1240 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 1245 Train loss: 0.037\n",
      "Epoch: 4/10 Iteration: 1250 Train loss: 0.041\n",
      "Val acc: 0.945\n",
      "Epoch: 4/10 Iteration: 1255 Train loss: 0.040\n",
      "Epoch: 4/10 Iteration: 1260 Train loss: 0.036\n",
      "Epoch: 4/10 Iteration: 1265 Train loss: 0.037\n",
      "Epoch: 4/10 Iteration: 1270 Train loss: 0.040\n",
      "Epoch: 4/10 Iteration: 1275 Train loss: 0.038\n",
      "Val acc: 0.942\n",
      "Epoch: 4/10 Iteration: 1280 Train loss: 0.042\n",
      "Epoch: 4/10 Iteration: 1285 Train loss: 0.040\n",
      "Epoch: 4/10 Iteration: 1290 Train loss: 0.036\n",
      "Epoch: 4/10 Iteration: 1295 Train loss: 0.037\n",
      "Epoch: 4/10 Iteration: 1300 Train loss: 0.039\n",
      "Val acc: 0.944\n",
      "Epoch: 4/10 Iteration: 1305 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 1310 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 1315 Train loss: 0.040\n",
      "Epoch: 4/10 Iteration: 1320 Train loss: 0.038\n",
      "Epoch: 4/10 Iteration: 1325 Train loss: 0.039\n",
      "Val acc: 0.941\n",
      "Epoch: 4/10 Iteration: 1330 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 1335 Train loss: 0.038\n",
      "Epoch: 4/10 Iteration: 1340 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 1345 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 1350 Train loss: 0.039\n",
      "Val acc: 0.940\n",
      "Epoch: 4/10 Iteration: 1355 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 1360 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1365 Train loss: 0.047\n",
      "Epoch: 5/10 Iteration: 1370 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1375 Train loss: 0.039\n",
      "Val acc: 0.951\n",
      "Epoch: 5/10 Iteration: 1380 Train loss: 0.038\n",
      "Epoch: 5/10 Iteration: 1385 Train loss: 0.037\n",
      "Epoch: 5/10 Iteration: 1390 Train loss: 0.041\n",
      "Epoch: 5/10 Iteration: 1395 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1400 Train loss: 0.039\n",
      "Val acc: 0.950\n",
      "Epoch: 5/10 Iteration: 1405 Train loss: 0.037\n",
      "Epoch: 5/10 Iteration: 1410 Train loss: 0.041\n",
      "Epoch: 5/10 Iteration: 1415 Train loss: 0.038\n",
      "Epoch: 5/10 Iteration: 1420 Train loss: 0.040\n",
      "Epoch: 5/10 Iteration: 1425 Train loss: 0.038\n",
      "Val acc: 0.951\n",
      "Epoch: 5/10 Iteration: 1430 Train loss: 0.038\n",
      "Epoch: 5/10 Iteration: 1435 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1440 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1445 Train loss: 0.035\n",
      "Epoch: 5/10 Iteration: 1450 Train loss: 0.037\n",
      "Val acc: 0.951\n",
      "Epoch: 5/10 Iteration: 1455 Train loss: 0.037\n",
      "Epoch: 5/10 Iteration: 1460 Train loss: 0.038\n",
      "Epoch: 5/10 Iteration: 1465 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1470 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1475 Train loss: 0.039\n",
      "Val acc: 0.951\n",
      "Epoch: 5/10 Iteration: 1480 Train loss: 0.040\n",
      "Epoch: 5/10 Iteration: 1485 Train loss: 0.036\n",
      "Epoch: 5/10 Iteration: 1490 Train loss: 0.036\n",
      "Epoch: 5/10 Iteration: 1495 Train loss: 0.041\n",
      "Epoch: 5/10 Iteration: 1500 Train loss: 0.036\n",
      "Val acc: 0.951\n",
      "Epoch: 5/10 Iteration: 1505 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1510 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1515 Train loss: 0.040\n",
      "Epoch: 5/10 Iteration: 1520 Train loss: 0.035\n",
      "Epoch: 5/10 Iteration: 1525 Train loss: 0.039\n",
      "Val acc: 0.951\n",
      "Epoch: 5/10 Iteration: 1530 Train loss: 0.036\n",
      "Epoch: 5/10 Iteration: 1535 Train loss: 0.038\n",
      "Epoch: 5/10 Iteration: 1540 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1545 Train loss: 0.037\n",
      "Epoch: 5/10 Iteration: 1550 Train loss: 0.042\n",
      "Val acc: 0.951\n",
      "Epoch: 5/10 Iteration: 1555 Train loss: 0.037\n",
      "Epoch: 5/10 Iteration: 1560 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1565 Train loss: 0.036\n",
      "Epoch: 5/10 Iteration: 1570 Train loss: 0.035\n",
      "Epoch: 5/10 Iteration: 1575 Train loss: 0.039\n",
      "Val acc: 0.951\n",
      "Epoch: 5/10 Iteration: 1580 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1585 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1590 Train loss: 0.035\n",
      "Epoch: 5/10 Iteration: 1595 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1600 Train loss: 0.038\n",
      "Val acc: 0.950\n",
      "Epoch: 5/10 Iteration: 1605 Train loss: 0.038\n",
      "Epoch: 5/10 Iteration: 1610 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 1615 Train loss: 0.037\n",
      "Epoch: 5/10 Iteration: 1620 Train loss: 0.038\n",
      "Epoch: 5/10 Iteration: 1625 Train loss: 0.039\n",
      "Val acc: 0.951\n",
      "Epoch: 5/10 Iteration: 1630 Train loss: 0.036\n",
      "Epoch: 6/10 Iteration: 1635 Train loss: 0.038\n",
      "Epoch: 6/10 Iteration: 1640 Train loss: 0.038\n",
      "Epoch: 6/10 Iteration: 1645 Train loss: 0.040\n",
      "Epoch: 6/10 Iteration: 1650 Train loss: 0.039\n",
      "Val acc: 0.952\n",
      "Epoch: 6/10 Iteration: 1655 Train loss: 0.036\n",
      "Epoch: 6/10 Iteration: 1660 Train loss: 0.039\n",
      "Epoch: 6/10 Iteration: 1665 Train loss: 0.038\n",
      "Epoch: 6/10 Iteration: 1670 Train loss: 0.037\n",
      "Epoch: 6/10 Iteration: 1675 Train loss: 0.039\n",
      "Val acc: 0.951\n",
      "Epoch: 6/10 Iteration: 1680 Train loss: 0.042\n",
      "Epoch: 6/10 Iteration: 1685 Train loss: 0.035\n",
      "Epoch: 6/10 Iteration: 1690 Train loss: 0.036\n",
      "Epoch: 6/10 Iteration: 1695 Train loss: 0.038\n",
      "Epoch: 6/10 Iteration: 1700 Train loss: 0.037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc: 0.952\n",
      "Epoch: 6/10 Iteration: 1705 Train loss: 0.037\n",
      "Epoch: 6/10 Iteration: 1710 Train loss: 0.036\n",
      "Epoch: 6/10 Iteration: 1715 Train loss: 0.037\n",
      "Epoch: 6/10 Iteration: 1720 Train loss: 0.037\n",
      "Epoch: 6/10 Iteration: 1725 Train loss: 0.037\n",
      "Val acc: 0.952\n",
      "Epoch: 6/10 Iteration: 1730 Train loss: 0.037\n",
      "Epoch: 6/10 Iteration: 1735 Train loss: 0.036\n",
      "Epoch: 6/10 Iteration: 1740 Train loss: 0.040\n",
      "Epoch: 6/10 Iteration: 1745 Train loss: 0.037\n",
      "Epoch: 6/10 Iteration: 1750 Train loss: 0.036\n",
      "Val acc: 0.952\n",
      "Epoch: 6/10 Iteration: 1755 Train loss: 0.034\n",
      "Epoch: 6/10 Iteration: 1760 Train loss: 0.038\n",
      "Epoch: 6/10 Iteration: 1765 Train loss: 0.038\n",
      "Epoch: 6/10 Iteration: 1770 Train loss: 0.041\n",
      "Epoch: 6/10 Iteration: 1775 Train loss: 0.036\n",
      "Val acc: 0.952\n",
      "Epoch: 6/10 Iteration: 1780 Train loss: 0.040\n",
      "Epoch: 6/10 Iteration: 1785 Train loss: 0.040\n",
      "Epoch: 6/10 Iteration: 1790 Train loss: 0.036\n",
      "Epoch: 6/10 Iteration: 1795 Train loss: 0.039\n",
      "Epoch: 6/10 Iteration: 1800 Train loss: 0.038\n",
      "Val acc: 0.952\n",
      "Epoch: 6/10 Iteration: 1805 Train loss: 0.038\n",
      "Epoch: 6/10 Iteration: 1810 Train loss: 0.035\n",
      "Epoch: 6/10 Iteration: 1815 Train loss: 0.038\n",
      "Epoch: 6/10 Iteration: 1820 Train loss: 0.035\n",
      "Epoch: 6/10 Iteration: 1825 Train loss: 0.036\n",
      "Val acc: 0.951\n",
      "Epoch: 6/10 Iteration: 1830 Train loss: 0.038\n",
      "Epoch: 6/10 Iteration: 1835 Train loss: 0.039\n",
      "Epoch: 6/10 Iteration: 1840 Train loss: 0.038\n",
      "Epoch: 6/10 Iteration: 1845 Train loss: 0.039\n",
      "Epoch: 6/10 Iteration: 1850 Train loss: 0.037\n",
      "Val acc: 0.952\n",
      "Epoch: 6/10 Iteration: 1855 Train loss: 0.039\n",
      "Epoch: 6/10 Iteration: 1860 Train loss: 0.040\n",
      "Epoch: 6/10 Iteration: 1865 Train loss: 0.038\n",
      "Epoch: 6/10 Iteration: 1870 Train loss: 0.036\n",
      "Epoch: 6/10 Iteration: 1875 Train loss: 0.037\n",
      "Val acc: 0.952\n",
      "Epoch: 6/10 Iteration: 1880 Train loss: 0.035\n",
      "Epoch: 6/10 Iteration: 1885 Train loss: 0.037\n",
      "Epoch: 6/10 Iteration: 1890 Train loss: 0.037\n",
      "Epoch: 6/10 Iteration: 1895 Train loss: 0.038\n",
      "Epoch: 6/10 Iteration: 1900 Train loss: 0.038\n",
      "Val acc: 0.952\n",
      "Epoch: 7/10 Iteration: 1905 Train loss: 0.035\n",
      "Epoch: 7/10 Iteration: 1910 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 1915 Train loss: 0.038\n",
      "Epoch: 7/10 Iteration: 1920 Train loss: 0.038\n",
      "Epoch: 7/10 Iteration: 1925 Train loss: 0.037\n",
      "Val acc: 0.952\n",
      "Epoch: 7/10 Iteration: 1930 Train loss: 0.038\n",
      "Epoch: 7/10 Iteration: 1935 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 1940 Train loss: 0.034\n",
      "Epoch: 7/10 Iteration: 1945 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 1950 Train loss: 0.038\n",
      "Val acc: 0.951\n",
      "Epoch: 7/10 Iteration: 1955 Train loss: 0.035\n",
      "Epoch: 7/10 Iteration: 1960 Train loss: 0.038\n",
      "Epoch: 7/10 Iteration: 1965 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 1970 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 1975 Train loss: 0.040\n",
      "Val acc: 0.952\n",
      "Epoch: 7/10 Iteration: 1980 Train loss: 0.036\n",
      "Epoch: 7/10 Iteration: 1985 Train loss: 0.036\n",
      "Epoch: 7/10 Iteration: 1990 Train loss: 0.034\n",
      "Epoch: 7/10 Iteration: 1995 Train loss: 0.035\n",
      "Epoch: 7/10 Iteration: 2000 Train loss: 0.038\n",
      "Val acc: 0.953\n",
      "Epoch: 7/10 Iteration: 2005 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 2010 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 2015 Train loss: 0.038\n",
      "Epoch: 7/10 Iteration: 2020 Train loss: 0.036\n",
      "Epoch: 7/10 Iteration: 2025 Train loss: 0.040\n",
      "Val acc: 0.952\n",
      "Epoch: 7/10 Iteration: 2030 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 2035 Train loss: 0.037\n",
      "Epoch: 7/10 Iteration: 2040 Train loss: 0.037\n",
      "Epoch: 7/10 Iteration: 2045 Train loss: 0.036\n",
      "Epoch: 7/10 Iteration: 2050 Train loss: 0.038\n",
      "Val acc: 0.952\n",
      "Epoch: 7/10 Iteration: 2055 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 2060 Train loss: 0.036\n",
      "Epoch: 7/10 Iteration: 2065 Train loss: 0.034\n",
      "Epoch: 7/10 Iteration: 2070 Train loss: 0.036\n",
      "Epoch: 7/10 Iteration: 2075 Train loss: 0.037\n",
      "Val acc: 0.952\n",
      "Epoch: 7/10 Iteration: 2080 Train loss: 0.034\n",
      "Epoch: 7/10 Iteration: 2085 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 2090 Train loss: 0.037\n",
      "Epoch: 7/10 Iteration: 2095 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 2100 Train loss: 0.036\n",
      "Val acc: 0.953\n",
      "Epoch: 7/10 Iteration: 2105 Train loss: 0.037\n",
      "Epoch: 7/10 Iteration: 2110 Train loss: 0.035\n",
      "Epoch: 7/10 Iteration: 2115 Train loss: 0.034\n",
      "Epoch: 7/10 Iteration: 2120 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 2125 Train loss: 0.036\n",
      "Val acc: 0.952\n",
      "Epoch: 7/10 Iteration: 2130 Train loss: 0.037\n",
      "Epoch: 7/10 Iteration: 2135 Train loss: 0.037\n",
      "Epoch: 7/10 Iteration: 2140 Train loss: 0.038\n",
      "Epoch: 7/10 Iteration: 2145 Train loss: 0.040\n",
      "Epoch: 7/10 Iteration: 2150 Train loss: 0.038\n",
      "Val acc: 0.952\n",
      "Epoch: 7/10 Iteration: 2155 Train loss: 0.038\n",
      "Epoch: 7/10 Iteration: 2160 Train loss: 0.039\n",
      "Epoch: 7/10 Iteration: 2165 Train loss: 0.035\n",
      "Epoch: 7/10 Iteration: 2170 Train loss: 0.037\n",
      "Epoch: 7/10 Iteration: 2175 Train loss: 0.039\n",
      "Val acc: 0.952\n",
      "Epoch: 8/10 Iteration: 2180 Train loss: 0.037\n",
      "Epoch: 8/10 Iteration: 2185 Train loss: 0.037\n",
      "Epoch: 8/10 Iteration: 2190 Train loss: 0.039\n",
      "Epoch: 8/10 Iteration: 2195 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2200 Train loss: 0.036\n",
      "Val acc: 0.953\n",
      "Epoch: 8/10 Iteration: 2205 Train loss: 0.036\n",
      "Epoch: 8/10 Iteration: 2210 Train loss: 0.036\n",
      "Epoch: 8/10 Iteration: 2215 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2220 Train loss: 0.041\n",
      "Epoch: 8/10 Iteration: 2225 Train loss: 0.040\n",
      "Val acc: 0.951\n",
      "Epoch: 8/10 Iteration: 2230 Train loss: 0.036\n",
      "Epoch: 8/10 Iteration: 2235 Train loss: 0.037\n",
      "Epoch: 8/10 Iteration: 2240 Train loss: 0.040\n",
      "Epoch: 8/10 Iteration: 2245 Train loss: 0.039\n",
      "Epoch: 8/10 Iteration: 2250 Train loss: 0.035\n",
      "Val acc: 0.952\n",
      "Epoch: 8/10 Iteration: 2255 Train loss: 0.037\n",
      "Epoch: 8/10 Iteration: 2260 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2265 Train loss: 0.037\n",
      "Epoch: 8/10 Iteration: 2270 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2275 Train loss: 0.037\n",
      "Val acc: 0.953\n",
      "Epoch: 8/10 Iteration: 2280 Train loss: 0.036\n",
      "Epoch: 8/10 Iteration: 2285 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2290 Train loss: 0.039\n",
      "Epoch: 8/10 Iteration: 2295 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2300 Train loss: 0.035\n",
      "Val acc: 0.953\n",
      "Epoch: 8/10 Iteration: 2305 Train loss: 0.037\n",
      "Epoch: 8/10 Iteration: 2310 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2315 Train loss: 0.035\n",
      "Epoch: 8/10 Iteration: 2320 Train loss: 0.036\n",
      "Epoch: 8/10 Iteration: 2325 Train loss: 0.038\n",
      "Val acc: 0.952\n",
      "Epoch: 8/10 Iteration: 2330 Train loss: 0.036\n",
      "Epoch: 8/10 Iteration: 2335 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2340 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2345 Train loss: 0.036\n",
      "Epoch: 8/10 Iteration: 2350 Train loss: 0.038\n",
      "Val acc: 0.953\n",
      "Epoch: 8/10 Iteration: 2355 Train loss: 0.036\n",
      "Epoch: 8/10 Iteration: 2360 Train loss: 0.039\n",
      "Epoch: 8/10 Iteration: 2365 Train loss: 0.039\n",
      "Epoch: 8/10 Iteration: 2370 Train loss: 0.036\n",
      "Epoch: 8/10 Iteration: 2375 Train loss: 0.038\n",
      "Val acc: 0.953\n",
      "Epoch: 8/10 Iteration: 2380 Train loss: 0.034\n",
      "Epoch: 8/10 Iteration: 2385 Train loss: 0.037\n",
      "Epoch: 8/10 Iteration: 2390 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2395 Train loss: 0.035\n",
      "Epoch: 8/10 Iteration: 2400 Train loss: 0.037\n",
      "Val acc: 0.953\n",
      "Epoch: 8/10 Iteration: 2405 Train loss: 0.034\n",
      "Epoch: 8/10 Iteration: 2410 Train loss: 0.037\n",
      "Epoch: 8/10 Iteration: 2415 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2420 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2425 Train loss: 0.034\n",
      "Val acc: 0.952\n",
      "Epoch: 8/10 Iteration: 2430 Train loss: 0.035\n",
      "Epoch: 8/10 Iteration: 2435 Train loss: 0.038\n",
      "Epoch: 8/10 Iteration: 2440 Train loss: 0.039\n",
      "Epoch: 8/10 Iteration: 2445 Train loss: 0.035\n",
      "Epoch: 9/10 Iteration: 2450 Train loss: 0.037\n",
      "Val acc: 0.953\n",
      "Epoch: 9/10 Iteration: 2455 Train loss: 0.037\n",
      "Epoch: 9/10 Iteration: 2460 Train loss: 0.036\n",
      "Epoch: 9/10 Iteration: 2465 Train loss: 0.035\n",
      "Epoch: 9/10 Iteration: 2470 Train loss: 0.037\n",
      "Epoch: 9/10 Iteration: 2475 Train loss: 0.036\n",
      "Val acc: 0.953\n",
      "Epoch: 9/10 Iteration: 2480 Train loss: 0.038\n",
      "Epoch: 9/10 Iteration: 2485 Train loss: 0.039\n",
      "Epoch: 9/10 Iteration: 2490 Train loss: 0.039\n",
      "Epoch: 9/10 Iteration: 2495 Train loss: 0.037\n",
      "Epoch: 9/10 Iteration: 2500 Train loss: 0.038\n",
      "Val acc: 0.953\n",
      "Epoch: 9/10 Iteration: 2505 Train loss: 0.036\n",
      "Epoch: 9/10 Iteration: 2510 Train loss: 0.036\n",
      "Epoch: 9/10 Iteration: 2515 Train loss: 0.037\n",
      "Epoch: 9/10 Iteration: 2520 Train loss: 0.039\n",
      "Epoch: 9/10 Iteration: 2525 Train loss: 0.035\n",
      "Val acc: 0.953\n",
      "Epoch: 9/10 Iteration: 2530 Train loss: 0.037\n",
      "Epoch: 9/10 Iteration: 2535 Train loss: 0.039\n",
      "Epoch: 9/10 Iteration: 2540 Train loss: 0.039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10 Iteration: 2545 Train loss: 0.037\n",
      "Epoch: 9/10 Iteration: 2550 Train loss: 0.036\n",
      "Val acc: 0.953\n",
      "Epoch: 9/10 Iteration: 2555 Train loss: 0.035\n",
      "Epoch: 9/10 Iteration: 2560 Train loss: 0.034\n",
      "Epoch: 9/10 Iteration: 2565 Train loss: 0.041\n",
      "Epoch: 9/10 Iteration: 2570 Train loss: 0.036\n",
      "Epoch: 9/10 Iteration: 2575 Train loss: 0.038\n",
      "Val acc: 0.953\n",
      "Epoch: 9/10 Iteration: 2580 Train loss: 0.038\n",
      "Epoch: 9/10 Iteration: 2585 Train loss: 0.038\n",
      "Epoch: 9/10 Iteration: 2590 Train loss: 0.040\n",
      "Epoch: 9/10 Iteration: 2595 Train loss: 0.036\n",
      "Epoch: 9/10 Iteration: 2600 Train loss: 0.037\n",
      "Val acc: 0.953\n",
      "Epoch: 9/10 Iteration: 2605 Train loss: 0.034\n",
      "Epoch: 9/10 Iteration: 2610 Train loss: 0.036\n",
      "Epoch: 9/10 Iteration: 2615 Train loss: 0.038\n",
      "Epoch: 9/10 Iteration: 2620 Train loss: 0.033\n",
      "Epoch: 9/10 Iteration: 2625 Train loss: 0.035\n",
      "Val acc: 0.954\n",
      "Epoch: 9/10 Iteration: 2630 Train loss: 0.038\n",
      "Epoch: 9/10 Iteration: 2635 Train loss: 0.035\n",
      "Epoch: 9/10 Iteration: 2640 Train loss: 0.038\n",
      "Epoch: 9/10 Iteration: 2645 Train loss: 0.036\n",
      "Epoch: 9/10 Iteration: 2650 Train loss: 0.034\n",
      "Val acc: 0.953\n",
      "Epoch: 9/10 Iteration: 2655 Train loss: 0.035\n",
      "Epoch: 9/10 Iteration: 2660 Train loss: 0.038\n",
      "Epoch: 9/10 Iteration: 2665 Train loss: 0.036\n",
      "Epoch: 9/10 Iteration: 2670 Train loss: 0.037\n",
      "Epoch: 9/10 Iteration: 2675 Train loss: 0.037\n",
      "Val acc: 0.953\n",
      "Epoch: 9/10 Iteration: 2680 Train loss: 0.036\n",
      "Epoch: 9/10 Iteration: 2685 Train loss: 0.037\n",
      "Epoch: 9/10 Iteration: 2690 Train loss: 0.037\n",
      "Epoch: 9/10 Iteration: 2695 Train loss: 0.037\n",
      "Epoch: 9/10 Iteration: 2700 Train loss: 0.038\n",
      "Val acc: 0.953\n",
      "Epoch: 9/10 Iteration: 2705 Train loss: 0.036\n",
      "Epoch: 9/10 Iteration: 2710 Train loss: 0.036\n",
      "Epoch: 9/10 Iteration: 2715 Train loss: 0.036\n",
      "Epoch: 9/10 Iteration: 2720 Train loss: 0.036\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        for ii, (batch_x, batch_y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
    "\n",
    "            feed = {inputs_: batch_x,\n",
    "                    labels_: batch_y,\n",
    "                    keep_prob: 0.5,\n",
    "                    initial_state: state}\n",
    "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
    "\n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "\n",
    "            if iteration%25==0:\n",
    "                val_acc = []\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                for batch_val_x, batch_val_y in get_batches(val_x, val_y, batch_size):\n",
    "                    feed = {inputs_: batch_val_x,\n",
    "                            labels_: batch_val_y,\n",
    "                            keep_prob: 1, \n",
    "                            initial_state: val_state}\n",
    "                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "\n",
    "                    val_acc.append(batch_acc)\n",
    "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "\n",
    "            \n",
    "            iteration +=1\n",
    "            saver.save(sess, \"checkpoints/final_sentiment.ckpt\")\n",
    "    saver.save(sess, \"checkpoints/final_sentiment.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And run the test data set through it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.954\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, \"checkpoints/final_sentiment.ckpt\")\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    for ii, (bat_test_x, bat_test_y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
    "        feed = {inputs_: bat_test_x,\n",
    "                labels_: bat_test_y,\n",
    "                keep_prob: 1,\n",
    "                initial_state: test_state}\n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 95.4% Accuracy! Good time to push this live."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
